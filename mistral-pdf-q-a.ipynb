{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14487426,"sourceType":"datasetVersion","datasetId":9253291}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install fastapi uvicorn pyngrok sentence-transformers pymupdf faiss-cpu \"transformers>=4.43\" \"accelerate>=0.33\" \"bitsandbytes>=0.43\" \"autoawq>=0.2.7\" torch --extra-index-url https://download.pytorch.org/whl/cu121","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T14:52:07.739664Z","iopub.execute_input":"2026-01-18T14:52:07.739987Z","iopub.status.idle":"2026-01-18T14:52:23.991310Z","shell.execute_reply.started":"2026-01-18T14:52:07.739960Z","shell.execute_reply":"2026-01-18T14:52:23.990556Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for autoawq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\n\nmodel_name=\"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer=AutoTokenizer.from_pretrained(model_name, use_fast=True)\nbnb_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\nmodel=AutoModelForCausalLM.from_pretrained(model_name,\n                                          quantization_config=bnb_config,\n                                           device_map=\"auto\").eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T14:52:23.993043Z","iopub.execute_input":"2026-01-18T14:52:23.993309Z","iopub.status.idle":"2026-01-18T14:58:00.723126Z","shell.execute_reply.started":"2026-01-18T14:52:23.993281Z","shell.execute_reply":"2026-01-18T14:58:00.722225Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1063a7784f2e4286b6aa2a2c1f3d7238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8c6d997318414788f3cd63502316ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7518066bb1c4c64b74ac58427a8489f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b011d16f9d34774a0f1be91ac3e1002"}},"metadata":{}},{"name":"stderr","text":"2026-01-18 14:52:48.640057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768747969.092915      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768747969.218697      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768747970.250629      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768747970.250660      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768747970.250663      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768747970.250665      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a2322d4950148ff8b38d2061d59e375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65b001d695c74bd9b8fd3820793486a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f82d870fb9548e1a567341205c77c2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e70f5dddf6041b787c635607514c83e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c035d0feea1458dbe9503010d4042fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3db75ad0c1824a6694b5f891c3e1e3a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846d4a8c5d5a411e9a6964264a0dc24a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d042171426a045bdafa1a9a3d2a938eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8aeb57810eb4273bda0372e6204959a"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"save_dir = \"mistral_nemo_instruct_2407_4bit_bnb\"\ntry:\n    model.save_pretrained(save_dir, safe_serialization=True)\n    tokenizer.save_pretrained(save_dir)\n    print(\"Saved quantized model to:\", save_dir)\nexcept Exception as e:\n    print(\"Save 4-bit not supported in this env:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T14:58:00.724428Z","iopub.execute_input":"2026-01-18T14:58:00.725427Z","iopub.status.idle":"2026-01-18T14:58:24.544774Z","shell.execute_reply.started":"2026-01-18T14:58:00.725391Z","shell.execute_reply":"2026-01-18T14:58:24.543453Z"}},"outputs":[{"name":"stdout","text":"Saved quantized model to: mistral_nemo_instruct_2407_4bit_bnb\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import time\nfrom pathlib import Path\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nsave_dir = \"/kaggle/working/mistral_nemo_instruct_2407_4bit_bnb\"\n\ndef load_model_and_tokenizer(path_or_id):\n    bnb_cfg = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_compute_dtype=torch.bfloat16,\n    )\n    tok = AutoTokenizer.from_pretrained(path_or_id, use_fast=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        path_or_id,\n        quantization_config=bnb_cfg,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n    )\n    return tok, model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:26:54.607637Z","iopub.execute_input":"2026-01-18T16:26:54.608275Z","iopub.status.idle":"2026-01-18T16:26:59.685180Z","shell.execute_reply.started":"2026-01-18T16:26:54.608240Z","shell.execute_reply":"2026-01-18T16:26:59.684374Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if Path(save_dir).exists():\n    print(f\"Loading local 4-bit checkpoint: {save_dir}\")\n    tok, model = load_model_and_tokenizer(save_dir)\nelse:\n    print(\"Local 4-bit checkpoint not found (saving likely not supported in this env).\")\n\ndef generate_text(prompt, max_new_tokens=128, temperature=0.2, top_p=0.95):\n    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n    t0 = time.time()\n    with torch.no_grad():\n        out = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=temperature,\n            top_p=top_p,\n            pad_token_id=tok.eos_token_id,\n        )\n    t1 = time.time()\n    text = tok.decode(out[0], skip_special_tokens=True)\n    print(f\"\\n--- Generation ({t1 - t0:.2f}s) ---\\n{text}\\n\")\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:26:59.686467Z","iopub.execute_input":"2026-01-18T16:26:59.686933Z","iopub.status.idle":"2026-01-18T16:27:13.718289Z","shell.execute_reply.started":"2026-01-18T16:26:59.686905Z","shell.execute_reply":"2026-01-18T16:27:13.717498Z"}},"outputs":[{"name":"stdout","text":"Loading local 4-bit checkpoint: /kaggle/working/mistral_nemo_instruct_2407_4bit_bnb\n","output_type":"stream"},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n2026-01-18 16:27:00.888300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768753620.911309     829 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768753620.916249     829 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768753620.929421     829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768753620.929435     829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768753620.929438     829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768753620.929440     829 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n  warnings.warn(warning_msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a89e4609406e4507a9374d2488907ec5"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport fitz  \nimport re\n\ndef extract_text_from_upload(pdf_input):\n    try:\n        if isinstance(pdf_input, str):\n            # If it's a string, it's a path\n            doc = fitz.open(pdf_input)\n        else:\n            # If it's not a string, it's bytes from the streamlit upload\n            doc = fitz.open(stream=pdf_input, filetype=\"pdf\")\n            \n        full_text = []\n        for page in doc:\n            text = page.get_text(\"text\")\n            text = re.sub(r'(?<=\\b\\w) (?=\\w\\b)', '', text) \n            text = re.sub(r'\\s+', ' ', text)\n            full_text.append(text)\n        doc.close()\n        return \"\\n\".join(full_text)\n    except Exception as e:\n        print(f\"Failed to parse PDF: {e}\")\n        return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:27:55.418577Z","iopub.execute_input":"2026-01-18T16:27:55.418896Z","iopub.status.idle":"2026-01-18T16:27:55.424823Z","shell.execute_reply.started":"2026-01-18T16:27:55.418866Z","shell.execute_reply":"2026-01-18T16:27:55.424046Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def chunk_text(text, chunk_size=500, overlap=50):\n    words = text.split()\n    chunks = []\n    for i in range(0, len(words), chunk_size - overlap):\n        chunk = \" \".join(words[i:i + chunk_size])\n        chunks.append(chunk)\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:27:55.729244Z","iopub.execute_input":"2026-01-18T16:27:55.729921Z","iopub.status.idle":"2026-01-18T16:27:55.733873Z","shell.execute_reply.started":"2026-01-18T16:27:55.729892Z","shell.execute_reply":"2026-01-18T16:27:55.733196Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def embed_chunks(chunks, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n    model = SentenceTransformer(model_name)\n    embeddings = model.encode(chunks, convert_to_numpy=True)\n    return model, embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:27:55.979884Z","iopub.execute_input":"2026-01-18T16:27:55.980182Z","iopub.status.idle":"2026-01-18T16:27:55.984676Z","shell.execute_reply.started":"2026-01-18T16:27:55.980122Z","shell.execute_reply":"2026-01-18T16:27:55.983990Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def create_faiss_index(embeddings):\n    dim = embeddings.shape[1]\n    index = faiss.IndexFlatL2(dim)\n    index.add(embeddings)\n    return index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:27:56.188359Z","iopub.execute_input":"2026-01-18T16:27:56.188639Z","iopub.status.idle":"2026-01-18T16:27:56.192994Z","shell.execute_reply.started":"2026-01-18T16:27:56.188612Z","shell.execute_reply":"2026-01-18T16:27:56.192101Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def search_index(query, model, index, chunks, k=5):\n    query_embedding = model.encode([query], convert_to_numpy=True)\n    distances, indices = index.search(query_embedding, k)\n    return [chunks[i] for i in indices[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:27:58.654583Z","iopub.execute_input":"2026-01-18T16:27:58.654895Z","iopub.status.idle":"2026-01-18T16:27:58.659220Z","shell.execute_reply.started":"2026-01-18T16:27:58.654867Z","shell.execute_reply":"2026-01-18T16:27:58.658534Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/aibook/Hands-on Machine Learning with Python Implement Neural Network Solutions with Scikit-learn and PyTorch (Ashwin Pajankar  Aditya Joshi) (Z-Library).pdf\"  \n\ntext = extract_text_from_upload(pdf_path)\nchunks = chunk_text(text,chunk_size=150, overlap=15)\n\nmodel_embeddings, embeddings = embed_chunks(chunks)\n\n\nindex = create_faiss_index(embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:27:58.924224Z","iopub.execute_input":"2026-01-18T16:27:58.924491Z","iopub.status.idle":"2026-01-18T16:28:02.079670Z","shell.execute_reply.started":"2026-01-18T16:27:58.924466Z","shell.execute_reply":"2026-01-18T16:28:02.079031Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"question1 = \"What is Regression?\"\ntop_chunks = search_index(question1, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:28:02.080998Z","iopub.execute_input":"2026-01-18T16:28:02.081259Z","iopub.status.idle":"2026-01-18T16:28:02.096559Z","shell.execute_reply.started":"2026-01-18T16:28:02.081236Z","shell.execute_reply":"2026-01-18T16:28:02.095941Z"}},"outputs":[{"name":"stdout","text":"\n--- Chunk 1 ---\nsystem that takes input text and learns how to classify the given text as â€œpositive,â€ â€œnegative,â€ or â€œneutral.â€ If you want to build a system to predict movie rating, you will probably collect movie descriptions, tags, genre information and other tags, and the final rating (out of ten), which will act as a label. Thus, the labels that are assigned are limited and clearly discreet and distinct. In some cases, you can have more than one label to be assigned to one data item â€“ these are called multiclass classification problems. Regression Regression is a supervised learning technique that tries to capture the relationship between two variables. We often have one or more independent variables, or the variables that we would always know, and we want to learn how to predict the value of a dependent variable. In regression problems, we want to predict a continuous real value; that means\n\n--- Chunk 2 ---\nvariable can be seen in the graph shown in Figure 7-1. Here, we are trying to model the relationship between marks scored by a student and the salary of the first job they got after graduation. Figure 7-1 Exploring the relationship between marks of students and salary By a simple look, you can visualize the linear relationship between the two despite several outliers. We attempt to find the line that best justifies all the points of the dataset as a whole. Finding the Regression Line In linear regression, our aim is to find a function that takes the value (or values) of the independent variable X as input and provides the value of the dependent variable y as output. Basic geometry tells us that an equation of a line is given by where m is the slope of the line and c is where the line meets the y axis.\n\n--- Chunk 3 ---\nyet important supervised learning methods. This chapter begins with an explanation of Linear Regression followed by a scikit-learn based experiment. We will also discuss a few measures to determine the quality of regression model. Next, we will discuss a classification method called Logistic Regression, learn a simple model and visualize its predictions in a decision boundary chart. Last, we will learn about Decision Trees which form the basis of a powerful suite of methods that are used for both classification and regression. We will explore a simple example and visualize the tree. Linear Regression Linear regression is a supervised learning method specifically to model the relationship between a dependent variable and one or more independent variables. This is an attempt to construct a linear function that outputs the value. A simple example with one independent variable can be seen in the graph shown in Figure 7-1. Here, we are trying\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"chunk = top_chunks[0]\n\nprompt = f\"Answer the next question: {question1} by reading the following text:{chunk}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:09:20.947661Z","iopub.execute_input":"2026-01-18T16:09:20.947893Z","iopub.status.idle":"2026-01-18T16:09:20.955703Z","shell.execute_reply.started":"2026-01-18T16:09:20.947866Z","shell.execute_reply":"2026-01-18T16:09:20.954901Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"answer1 = generate_text(prompt, temperature=0.4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:09:20.956668Z","iopub.execute_input":"2026-01-18T16:09:20.956925Z","iopub.status.idle":"2026-01-18T16:09:30.547753Z","shell.execute_reply.started":"2026-01-18T16:09:20.956890Z","shell.execute_reply":"2026-01-18T16:09:30.547082Z"}},"outputs":[{"name":"stdout","text":"\n--- Generation (9.57s) ---\nAnswer the next question: What is Regression? by reading the following text:system that takes input text and learns how to classify the given text as â€œpositive,â€ â€œnegative,â€ or â€œneutral.â€ If you want to build a system to predict movie rating, you will probably collect movie descriptions, tags, genre information and other tags, and the final rating (out of ten), which will act as a label. Thus, the labels that are assigned are limited and clearly discreet and distinct. In some cases, you can have more than one label to be assigned to one data item â€“ these are called multiclass classification problems. Regression Regression is a supervised learning technique that tries to capture the relationship between two variables. We often have one or more independent variables, or the variables that we would always know, and we want to learn how to predict the value of a dependent variable. In regression problems, we want to predict a continuous real value; that means the output will be a real number. For example, if you want to predict the price of a house based on its size, you will use regression techniques. In regression problems, we do not have predefined classes to assign to the data. Instead, we try to predict the value of the dependent variable based on the independent variables.\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"question2 = \"What are the types of regression?\"\ntop_chunks = search_index(question2, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:09:30.548588Z","iopub.execute_input":"2026-01-18T16:09:30.548803Z","iopub.status.idle":"2026-01-18T16:09:30.562827Z","shell.execute_reply.started":"2026-01-18T16:09:30.548780Z","shell.execute_reply":"2026-01-18T16:09:30.562131Z"}},"outputs":[{"name":"stdout","text":"\n--- Chunk 1 ---\nsystem that takes input text and learns how to classify the given text as â€œpositive,â€ â€œnegative,â€ or â€œneutral.â€ If you want to build a system to predict movie rating, you will probably collect movie descriptions, tags, genre information and other tags, and the final rating (out of ten), which will act as a label. Thus, the labels that are assigned are limited and clearly discreet and distinct. In some cases, you can have more than one label to be assigned to one data item â€“ these are called multiclass classification problems. Regression Regression is a supervised learning technique that tries to capture the relationship between two variables. We often have one or more independent variables, or the variables that we would always know, and we want to learn how to predict the value of a dependent variable. In regression problems, we want to predict a continuous real value; that means\n\n--- Chunk 2 ---\nvariable can be seen in the graph shown in Figure 7-1. Here, we are trying to model the relationship between marks scored by a student and the salary of the first job they got after graduation. Figure 7-1 Exploring the relationship between marks of students and salary By a simple look, you can visualize the linear relationship between the two despite several outliers. We attempt to find the line that best justifies all the points of the dataset as a whole. Finding the Regression Line In linear regression, our aim is to find a function that takes the value (or values) of the independent variable X as input and provides the value of the dependent variable y as output. Basic geometry tells us that an equation of a line is given by where m is the slope of the line and c is where the line meets the y axis.\n\n--- Chunk 3 ---\ndependent variable. In regression problems, we want to predict a continuous real value; that means the target value can have infinite possibilities unlike classification that has a selected few. An example of regression is a system to predict the value of a stock the next day based on the value and volume traded on the previous day. Supervised learning is specifically used in prediction problems where you want to obtain the output for the given data based on past experiences. It is used in use cases like image categorization, sentiment analysis, spam filtering, etc. Unsupervised Learning Unsupervised learning is the set of approaches that focus on finding hidden patterns and insights from the given dataset. In such cases, we do not require labelled data. The goal of such approaches is to find the underlying structure of the data, simplify or compress the dataset, or group the data according to inherent\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"chunk = top_chunks[0]\n\nprompt = f\"Answer the next question: {question2} by reading the following text:{chunk}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:09:30.563798Z","iopub.execute_input":"2026-01-18T16:09:30.564019Z","iopub.status.idle":"2026-01-18T16:09:30.572533Z","shell.execute_reply.started":"2026-01-18T16:09:30.563997Z","shell.execute_reply":"2026-01-18T16:09:30.571981Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"answer2 = generate_text(prompt, temperature=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:09:30.573508Z","iopub.execute_input":"2026-01-18T16:09:30.573807Z","iopub.status.idle":"2026-01-18T16:09:47.038097Z","shell.execute_reply.started":"2026-01-18T16:09:30.573773Z","shell.execute_reply":"2026-01-18T16:09:47.037375Z"}},"outputs":[{"name":"stdout","text":"\n--- Generation (16.45s) ---\nAnswer the next question: What are the types of regression? by reading the following text:system that takes input text and learns how to classify the given text as â€œpositive,â€ â€œnegative,â€ or â€œneutral.â€ If you want to build a system to predict movie rating, you will probably collect movie descriptions, tags, genre information and other tags, and the final rating (out of ten), which will act as a label. Thus, the labels that are assigned are limited and clearly discreet and distinct. In some cases, you can have more than one label to be assigned to one data item â€“ these are called multiclass classification problems. Regression Regression is a supervised learning technique that tries to capture the relationship between two variables. We often have one or more independent variables, or the variables that we would always know, and we want to learn how to predict the value of a dependent variable. In regression problems, we want to predict a continuous real value; that means the output value can be any value in the range. For instance, you want to predict the price of a house based on various features such as the number of bedrooms, bathrooms, square footage, etc. Here, the dependent variable is price and independent variables are bedrooms, bathrooms, square footage, etc. Some common types of regression techniques include linear regression, logistic regression, polynomial regression, and others.\n\nThe text discusses two main types of supervised learning techniques: classification and regression. Classification involves assigning discrete labels to data items, while regression involves predicting a continuous real value based on one or more independent variables. The text mentions several types of\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"NGROK_TOKEN = \"31CaKcK72zQFZ5v6dgDeAWmtRTg_T8zD7FHZNe1WYBKrsNwN\" #paste your NGROK Token from the website\nAPI_KEY = \"secret123\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:28:10.162722Z","iopub.execute_input":"2026-01-18T16:28:10.163364Z","iopub.status.idle":"2026-01-18T16:28:10.166648Z","shell.execute_reply.started":"2026-01-18T16:28:10.163330Z","shell.execute_reply":"2026-01-18T16:28:10.166044Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from fastapi import FastAPI, Request, HTTPException, File, UploadFile, Form\nimport uvicorn, threading, socket, json, re, fitz, traceback\nfrom pyngrok import ngrok, conf\n\napp = FastAPI()\n\n# ---  SETTINGS & STATE ---\nPORT = 8000 \n\nclass PDFState:\n    def __init__(self):\n        self.pdf_hash = None\n        self.chunks = []\n        self.index = None\n\nstate = PDFState()\n\n# ---  BACKEND LOGIC ---\n@app.post(\"/generate\")\nasync def gen(\n    request: Request, \n    prompt: str = Form(...), \n    history: str = Form(\"[]\"), \n    file: UploadFile = File(...)\n):\n    if request.headers.get(\"authorization\") != f\"Bearer {API_KEY}\":\n        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n\n    try:\n        pdf_bytes = await file.read()\n        current_hash = hash(pdf_bytes)\n\n        # Re-index if new file\n        if state.pdf_hash != current_hash:\n            text = extract_text_from_upload(pdf_bytes)\n            state.chunks = chunk_text(text, chunk_size=150, overlap=15)\n            embeddings = model_embeddings.encode(state.chunks, convert_to_numpy=True)\n            state.index = create_faiss_index(embeddings)\n            state.pdf_hash = current_hash\n\n        # Retrieval\n        query_vec = model_embeddings.encode([prompt], convert_to_numpy=True)\n        _, indices = state.index.search(query_vec, k=2)\n        context = \" \".join([state.chunks[i] for i in indices[0]])\n\n        chat_history = json.loads(history)\n        \n        # If history is empty, it's a fresh start - we can be more aggressive with speed\n        is_fresh_chat = len(chat_history) == 0\n        \n        if is_fresh_chat:\n            print(\"ğŸ§¹ Fresh chat detected. Performance optimized.\")        # Inside your gen function in Kaggle:\n\n        history_text = \"\"\n        for m in chat_history[-3:]:\n            history_text += f\"{m['role'].upper()}: {m['content']}\\n\"\n        \n        system_instructions = \"You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\"\n        \n        llm_prompt = f\"<s>[INST] {system_instructions}\\n\\nCONTEXT:\\n{context}\\n\\nHISTORY:\\n{history_text}\\n\\nQUESTION: {prompt} \\n\\nAnswer:[/INST]\"\n\n\n        raw_response = generate_text(llm_prompt, max_new_tokens=1024, temperature=0.5)\n        # Use rsplit to find the LAST occurrence of \"Answer:\"\n        # maxsplit=1 means it only splits once, at the very last \"Answer:\" it finds\n        if \"Answer:\" in raw_response:\n            clean_answer = raw_response.rsplit(\"Answer:\", 1)[-1].strip()\n        elif \"[/INST]\" in raw_response:\n            # Fallback: if \"Answer:\" isn't there, take everything after the instruction\n            clean_answer = raw_response.split(\"[/INST]\")[-1].strip()\n        else:\n            clean_answer = raw_response.strip()\n        \n        clean_answer = clean_answer.split(\"Question:\")[0].strip()\n        \n        return {\"response\": clean_answer}\n    except Exception as e: # <--- THIS WAS MISSING\n        print(traceback.format_exc())\n        return {\"response\": f\"Internal Error: {str(e)}\"}\n\nngrok.kill()\nconf.get_default().auth_token = NGROK_TOKEN\n\npublic_url = ngrok.connect(PORT).public_url\nprint(f\"\\nğŸš€ NEW URL: {public_url}\\n\")\n\ndef run():\n    uvicorn.run(app, host=\"0.0.0.0\", port=PORT)\n\nthreading.Thread(target=run, daemon=True).start()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T16:28:39.156933Z","iopub.execute_input":"2026-01-18T16:28:39.157261Z","iopub.status.idle":"2026-01-18T16:28:40.020787Z","shell.execute_reply.started":"2026-01-18T16:28:39.157230Z","shell.execute_reply":"2026-01-18T16:28:40.019670Z"}},"outputs":[{"name":"stdout","text":"\nğŸš€ NEW URL: https://ungoaded-subdorsally-bethanie.ngrok-free.dev\n\n","output_type":"stream"},{"name":"stderr","text":"INFO:     Started server process [829]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"\n--- Generation (7.37s) ---\n You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\n\nCONTEXT:\nbelong to the first type (Setosa), which have been correctly classified. However, there are 11 samples in the second type, out of which ten have been correctly classified, and one has been classified as the third type. Then there are 12 samples, all of which are correctly identified as the third type. sklearn.metrics also contains functions for precision, recall, and F-measure. All these functions take at least two arguments: the actual class labels and the predicted class labels. If you have more than two classes, you can give the additional function parameter for average, which may contain one of the following values: binary: Default, the function only reports the results for the positive class labels. micro: Calculate metrics globally by counting the total true positives, false negatives, and false positives. macro: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account. weighted: of words or an audio signal, which may yield a fixed size output like sentiment polarity (positive or negative label). Many to Many Many-to-many RNNs are of two types. The first type is the RNNs in which the input size is equal to the output size â€“ thus in a manner, one output being produced for each item of input sequence. One popular example is sequence labelling, or entity recognition. For each word in a sentence, we generate labels like a Person Name, Location, Organization, or any Other word. The other type of RNNs may produce output sequence of a different size compared to the input sequence. These are highly helpful in machine translation, where each word in one language may not be directly mapped to a word in the second language, but how the words appear in a sequence produces a meaning in the target language. Thus, based on\n\nHISTORY:\nUSER: How many types of ML?\n\n\nQUESTION: How many types of ML? \n\nAnswer:Two types of ML algorithms are mentioned in the context provided: supervised learning and unsupervised learning.\n\nINFO:     156.202.15.182:0 - \"POST /generate HTTP/1.1\" 200 OK\n\n--- Generation (13.95s) ---\n You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\n\nCONTEXT:\nto One One to one is the form that doesnâ€™t require recurrent units, and each input is used by a hidden layer, followed by the output layer. These are the plain neural networks that deal with a fixed size of the input to the fixed size of the output, where they are independent of previous information/output. One to Many These recurrent neural networks take a fixed size of input and produce a sequence of data as output. These are used in solving problems like image captioning and music generation. The input is a static size, for example, an image, and the output is a sequence of words. Many to One These recurrent neural networks take a sequence of information as input and produce output of a fixed size. Thus, input should be either a sequence of words or an audio signal, which may yield a fixed size output like sentiment of words or an audio signal, which may yield a fixed size output like sentiment polarity (positive or negative label). Many to Many Many-to-many RNNs are of two types. The first type is the RNNs in which the input size is equal to the output size â€“ thus in a manner, one output being produced for each item of input sequence. One popular example is sequence labelling, or entity recognition. For each word in a sentence, we generate labels like a Person Name, Location, Organization, or any Other word. The other type of RNNs may produce output sequence of a different size compared to the input sequence. These are highly helpful in machine translation, where each word in one language may not be directly mapped to a word in the second language, but how the words appear in a sequence produces a meaning in the target language. Thus, based on\n\nHISTORY:\nUSER: How many types of ML?\nASSISTANT: Two types of ML algorithms are mentioned in the context provided: supervised learning and unsupervised learning.\nUSER: Tell me more about the first type\n\n\nQUESTION: Tell me more about the first type \n\nAnswer:The first type of Many-to-Many RNNs is where the input size equals the output size. This means that for each item in the input sequence, there is a corresponding output generated. A popular example of this type is sequence labeling or entity recognition. In this case, for each word in a sentence, the model generates labels such as Person Name, Location, Organization, or Other.\n\nINFO:     156.202.15.182:0 - \"POST /generate HTTP/1.1\" 200 OK\n\n--- Generation (6.60s) ---\n You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\n\nCONTEXT:\naround the world. Machine learning is the science of making computers able to act based on available data without being explicitly programmed to act a certain way. The field of learning from data has been evolving over the past half-century. However, due to the exponential rise in available quantity and quality of data in the past decade, and the available computing resources, we have seen an advent of sophisticated AI agents, self-driving cars, highly intelligent spam filtering, picture tagging applications, personalized web search, and so on. The primary reason for this revolution in technology is being attributed to machine learning. The most accepted definition of machine learning is given by Tom Mitchell. A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. â€”Tom popular library used for machine learning which will be the primary focus of this section of the book. We will begin with installation and understand the top-level architecture and API style that most of the components of Scikit-learn use. We will experiment with a simple example; however, the details will be explained in the relevant future chapters. Learning from Data A general notion of machine learning is to focus on the process of learning from data to discover hidden patterns or predict future events. There are two basic approaches within machine learning, namely, supervised learning and unsupervised learning. The main difference is one uses labelled data to help predict outcomes while the other does not. Supervised Learning Supervised learning is the set of approaches that requires an explicit label containing the correct expected output for each row in the data through which we want to learn. These labels are either\n\nHISTORY:\nUSER: Tell me more about the first type\nASSISTANT: The first type of Many-to-Many RNNs is where the input size equals the output size. This means that for each item in the input sequence, there is a corresponding output generated. A popular example of this type is sequence labeling or entity recognition. In this case, for each word in a sentence, the model generates labels such as Person Name, Location, Organization, or Other.\nUSER: I'm talking about the Supervised learning\n\n\n\nQUESTION: I'm talking about the Supervised learning\n \n\nAnswer:Supervised learning uses labeled data to predict outcomes.\n\nINFO:     156.202.15.182:0 - \"POST /generate HTTP/1.1\" 200 OK\n\n--- Generation (12.41s) ---\n You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\n\nCONTEXT:\neach row in the data through which we want to learn. These labels are either written by hand by domain experts or obtained from previous records or generated by software logs. Such datasets are used to supervise algorithms into classifying the data or predicting outcomes. Classification Classification is a suite of supervised learning methods that aim to assign a discrete class label chosen out of a predefined limited set of options (two or more). An example of such labels is a system that monitors the financial transactions and validates each transaction for any kind of fraud. The past data is required, which contains regular transactions as well as fraudulent transactions explicitly stating which data item (or row) is fraudulent. The possible classes are â€œfraudulent transactionâ€ or â€œnonfraudulent transaction.â€ Another common example is a sentiment analysis system that takes input text and learns how to classify the given text as â€œpositive,â€ popular library used for machine learning which will be the primary focus of this section of the book. We will begin with installation and understand the top-level architecture and API style that most of the components of Scikit-learn use. We will experiment with a simple example; however, the details will be explained in the relevant future chapters. Learning from Data A general notion of machine learning is to focus on the process of learning from data to discover hidden patterns or predict future events. There are two basic approaches within machine learning, namely, supervised learning and unsupervised learning. The main difference is one uses labelled data to help predict outcomes while the other does not. Supervised Learning Supervised learning is the set of approaches that requires an explicit label containing the correct expected output for each row in the data through which we want to learn. These labels are either\n\nHISTORY:\nUSER: I'm talking about the Supervised learning\n\nASSISTANT: Supervised learning uses labeled data to predict outcomes.\nUSER: Okay that's great! What're the types of supervised learning?\n\n\nQUESTION: Okay that's great! What're the types of supervised learning? \n\nAnswer:The types of supervised learning include:\n\n1. **Regression**: Used for predicting continuous numerical values. Examples include linear regression, polynomial regression, and support vector regression.\n2. **Classification**: Used for predicting discrete labels or categories. Examples include logistic regression, decision trees, random forests, support vector machines (SVM), and neural networks.\n\nINFO:     156.202.15.182:0 - \"POST /generate HTTP/1.1\" 200 OK\n\n--- Generation (45.69s) ---\n You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\n\nCONTEXT:\nof the city of the university the person graduated in and the annual salary they are getting in their primary full-time job. Both the columns contain data that might have an impact in the analysis of the predictive systems that will be built. However, there is a major distinction in terms of what you can do with each column. You might say that person A earns twice that of person B. All the basic operations can be applied on these. But when you look at the city of their university, the only operation you can apply is to see whether person A and person B studied in the same city. There are primarily two types of data variables based on this distinction. 1. Continuous variables, which can take any positive or negative real number. These variables are not limited to possible values, and the level of preciseness depends on the variable may obtain and the arithmetic operations that can be applied on them. In this manner, variables can be thought as being on one of the four scales â€“ nominal, ordinal, interval, or ratio. Nominal Data Nominal data is a type of data that can take any arbitrary nonnumerical values. This kind of data can neither be measured nor compared. Nominal data can be qualitative or quantitative; however, due to their nature, no arithmetic operations can be applied on these. For example, names, address, gender, etc., can be regarded as nominal data attributes. The only statistical central tendency that can be studied is the mode, or the quantity that occurs most often in the attribute being studied. Mean and median are meaningless for nominal data. Ordinal Data Ordinal data is a type of data whose values follow an order. Though the values donâ€™t have a notion of differences and increments,\n\nHISTORY:\nUSER: Okay that's great! What're the types of supervised learning?\nASSISTANT: The types of supervised learning include:\n\n1. **Regression**: Used for predicting continuous numerical values. Examples include linear regression, polynomial regression, and support vector regression.\n2. **Classification**: Used for predicting discrete labels or categories. Examples include logistic regression, decision trees, random forests, support vector machines (SVM), and neural networks.\nUSER: Tell me about the types of each of them\n\n\nQUESTION: Tell me about the types of each of them \n\nAnswer:**Regression:**\n\n1. **Linear Regression**: Uses a linear relationship between inputs and outputs. Can be simple (one input), multiple (many inputs), or polynomial (nonlinear transformation of inputs).\n2. **Logistic Regression**: Uses a logistic function to predict categorical outputs based on linear combinations of inputs.\n3. **Support Vector Regression (SVR)**: Uses support vectors to fit a line or curve to the data, minimizing the error while maximizing the margin.\n4. **Decision Tree Regression**: Creates a tree-based model where each internal node represents a feature, each branch represents a decision rule, and each leaf node represents a value.\n\n**Classification:**\n\n1. **Logistic Regression**: As mentioned above, uses a logistic function to predict categorical outputs.\n2. **Decision Trees**: Creates a tree-based model where each internal node represents a feature, each branch represents a decision rule, and each leaf node represents a class label.\n3. **Random Forest**: An ensemble of decision trees, trained on different subsets of the data and features, to improve predictive accuracy.\n4. **Support Vector Machines (SVM)**: Uses support vectors to find the optimal boundary or hyperplane that separates classes.\n5. **Naive Bayes**: Based on Bayes' theorem, uses probability estimates to classify inputs into categories.\n6. **K-Nearest Neighbors (KNN)**: Classifies objects based on the majority vote of its k nearest neighbors in the feature space.\n7. **Neural Networks**: Inspired by the human brain, uses layers of interconnected nodes to learn and classify complex patterns.\n8. **K-Means Clustering**: Although not strictly a classification algorithm, it can be used for classification by assigning data points to clusters based on their similarity.\n\nINFO:     156.202.15.182:0 - \"POST /generate HTTP/1.1\" 200 OK\n\n--- Generation (11.95s) ---\n You are a helpful AI assistant. Answer the question using ONLY the context provided. Do not repeat history or context.\n\nCONTEXT:\neach row in the data through which we want to learn. These labels are either written by hand by domain experts or obtained from previous records or generated by software logs. Such datasets are used to supervise algorithms into classifying the data or predicting outcomes. Classification Classification is a suite of supervised learning methods that aim to assign a discrete class label chosen out of a predefined limited set of options (two or more). An example of such labels is a system that monitors the financial transactions and validates each transaction for any kind of fraud. The past data is required, which contains regular transactions as well as fraudulent transactions explicitly stating which data item (or row) is fraudulent. The possible classes are â€œfraudulent transactionâ€ or â€œnonfraudulent transaction.â€ Another common example is a sentiment analysis system that takes input text and learns how to classify the given text as â€œpositive,â€ classification in Python Support vector machines (SVM) classifier T Tanh activation function Test dataset Time series prediction Tokenization torchvision.datasets() Training and testing processes Training dataset Transformation nominal attributes nonnumeric features into numeric ordinal attributes Transform method True negatives (TN) True positives (TP) Type 1/Type 2 Error U, V Underfitting Unsupervised learning Unsupervised learning methods clustering See Clustering dimensionality reduction FP mining W, X, Y, Z Weak learners\n\nHISTORY:\nUSER: Tell me about the types of classification\n\n\nQUESTION: Tell me about the types of classification \n\nAnswer:The types of classification mentioned in the context are:\n\n1. **Binary Classification**: Assigning one of two possible classes (e.g., \"fraudulent transaction\" or \"nonfraudulent transaction\").\n2. **Multi-class Classification**: Assigning one of three or more classes (e.g., classifying text sentiment as \"positive,\" \"neutral,\" or \"negative\").\n\nINFO:     156.202.15.182:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}